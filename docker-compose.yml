version: '3.8'

services:
  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chroma
    ports:
      - "8000:8000"
    volumes:
      - ./chroma_data:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
      - CHROMA_PERSIST_PATH=/chroma/chroma
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 90s

  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama_data:/root/.ollama  # Persist models
    healthcheck:
        test: ["CMD", "ollama", "ps"]
        interval: 10s
        timeout: 5s
        retries: 5
    logging:
      driver: "none"  # This is the new line that stops the spam

  pii-filter:
    build: ./PII
    container_name: pii-filter
    depends_on:
      rabbitmq:
        condition: service_healthy
    environment:
      - PYTHONUNBUFFERED=1

  rag-core:
    build: ./RAG-Core
    container_name: rag-core
    depends_on:
      rabbitmq:
        condition: service_healthy
      chroma:
        condition: service_started
    environment:
      - PYTHONUNBUFFERED=1

  llm-connector:
    build: ./LLM-Connector
    container_name: llm-connector
    depends_on:
      rabbitmq:
        condition: service_healthy
      ollama:
        condition: service_healthy
    environment:
      - PYTHONUNBUFFERED=1